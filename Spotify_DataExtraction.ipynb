{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c237307",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "author: Liang-Yun Cheng & Federico Cimini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809a596",
   "metadata": {},
   "source": [
    "### Secition I: Data Extraction from Spotify\n",
    "We recommend not to re-run this section as the API might take sometime to loop through 2000+ songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192613c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spotipy\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f436a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up API connect with client id & passpord\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=\"20053ba0f21d4da7be037777d0276be0\",\n",
    "                                                           client_secret=\"63d4eda7b4054e64ae1725955ada81cb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c7596",
   "metadata": {},
   "source": [
    "Spotify API returns json-type data. We will need to find the keys inside the nested dictionary to extract selected field information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19054d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_playlist = [\"37i9dQZF1DXcBWIGoYBM5M\", '37i9dQZEVXbMDoHDwVN2tF', '37i9dQZF1DX0XUsuxWHRQd', \n",
    "                '37i9dQZF1DX10zKzsJ2jva','37i9dQZF1DWXRqgorJj26U','37i9dQZF1DWTmvXBN4DgpA'] ## last id is playlist 2000\n",
    "\n",
    "# list to store all tracks and its info extracted\n",
    "track_list = []\n",
    "\n",
    "def extract_track_info(playlist_info, track_list):\n",
    "    ''' Tracks are stored under the dictionary key \"items\"\n",
    "      Loop through each tracks and extract track info \n",
    "      playlist_info: a json of playlist info\n",
    "      track_list: a list of list to store all tracks info extracted\n",
    "    '''\n",
    "    for tracks in playlist_info['items']:\n",
    "        track = tracks['track']\n",
    "        track_id = track['id']\n",
    "        track_name = track['name']\n",
    "        artist_name = track['artists'][0]['name']\n",
    "        artist_id = track['artists'][0]['id']\n",
    "        track_popularity = track['popularity']\n",
    "        track_release_date = track['album']['release_date']\n",
    "        track_list.append([track_id, track_name, artist_name, artist_id, track_popularity, track_release_date])\n",
    "\n",
    "'''loop through the playlists to extract tracks'''\n",
    "for playlist in top_playlist: \n",
    "    playlist_info = sp.playlist_items(playlist) # limit 100 songs\n",
    "    # extract each track info for first page\n",
    "    extract_track_info(playlist_info, track_list)\n",
    "    # check to see if playlist has more than 1 page\n",
    "    while playlist_info['next']:\n",
    "    # if more pages exists, then extract each track info for each subsequent pages\n",
    "    # update [playlist_info] variable to be the next page's info\n",
    "        playlist_info = sp.next(playlist_info) # parameter is the current page info\n",
    "        extract_track_info(playlist_info,track_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96dbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of list to a df\n",
    "tracks_df = pd.DataFrame(track_list, columns = ['track_id',\n",
    "                                                'track_name',\n",
    "                                                'artist_name',\n",
    "                                                'artist_id',\n",
    "                                                'track_popularity',\n",
    "                                                'release_date'])\n",
    "tracks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1527d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated songs\n",
    "tracks_df.drop_duplicates(inplace = True)\n",
    "tracks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get artist genres\n",
    "artist_list_df = tracks_df[['artist_id']].drop_duplicates()\n",
    "artist_list = []\n",
    "for id in artist_list_df['artist_id']:\n",
    "    artist_info = sp.artist(id)\n",
    "    genres = \", \".join(artist_info['genres'])\n",
    "    artist_list.append([id,genres])\n",
    "\n",
    "# convert list of list to df    \n",
    "artist_df = pd.DataFrame(artist_list, columns =['artist_id','genres'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c754af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artist_df.shape)\n",
    "artist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5009837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get audio features \n",
    "feature_df = pd.DataFrame()\n",
    "for tracks in tracks_df['track_id']:\n",
    "    feature_data = sp.audio_features(tracks)\n",
    "    feature_data_df = pd.DataFrame.from_dict(feature_data)\n",
    "    feature_df = pd.concat([feature_df,feature_data_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_df.shape)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tracks info table with track audio feature info\n",
    "tracks_feature_df = tracks_df.merge(feature_df, how = \"left\", left_on= \"track_id\", right_on= \"id\") \\\n",
    "                             .merge(artist_df, how = \"left\", left_on = 'artist_id', right_on = \"artist_id\")\n",
    "\n",
    "# drop unused columns\n",
    "tracks_feature_df.drop(['type','id','track_href','analysis_url','time_signature'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f865a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up release date column to show the decade \n",
    "tracks_feature_df['release_decade'] = tracks_feature_df['release_date'].str.slice(0,4) \\\n",
    "                                                                       .astype('int32') \\\n",
    "                                                                       .div(10) \\\n",
    "                                                                       .apply(np.floor) \\\n",
    "                                                                       .mul(10) \\\n",
    "                                                                       .astype('int32')\n",
    "                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a45ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export tracks_feature_df to csv\n",
    "import os  \n",
    "os.makedirs('Downloads', exist_ok=True)  \n",
    "tracks_feature_df.to_csv('Downloads/tracks_feature_df_phase1.csv') # file can be found in Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3e4db",
   "metadata": {},
   "source": [
    "## Section II:  EDA\n",
    "The section below can be runned by importing \"tracks_feature_df_phase1\" data.\n",
    "In the following section, we will ... \n",
    "- remove highly correlated columns\n",
    "- identify commonly used [genre] terms\n",
    "- perform k-means clustering (and conduct standard scaler and PCA before running k-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d369ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_feature_df = pd.read_csv('tracks_feature_df_phase1.csv')\n",
    "tracks_feature_df.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "tracks_feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977af8f",
   "metadata": {},
   "source": [
    "### What are the popular genres?\n",
    "For the [genres] drop-down list, we wanted to know the most common genres. We used the following two approaches to visualize the most common terms used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bba61",
   "metadata": {},
   "source": [
    "#### Approach 1: Count number of original catetgories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA for null genres to avoid error when looping through the list split\n",
    "genre_list = tracks_feature_df['genres'].fillna(\"NA\").tolist()\n",
    "genre_list_cleaned = []\n",
    "genre_dict = {}\n",
    "\n",
    "for item in genre_list:\n",
    "    split = item.split(sep = ',')\n",
    "    genre_list_cleaned.extend(split)\n",
    "\n",
    "for i in genre_list_cleaned:\n",
    "    genre_dict[i] = genre_dict.get(i, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08d8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wordcloud to visualize term frequency\n",
    "plt.subplots(figsize = (15,6))\n",
    "\n",
    "wordcloud = WordCloud (\n",
    "                    background_color = 'white',\n",
    "                    width = 512,\n",
    "                    height = 384\n",
    "                        ).generate_from_frequencies(genre_dict)\n",
    "plt.imshow(wordcloud) # show wordcloud\n",
    "plt.axis('off') # to hide x and y axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc229a81",
   "metadata": {},
   "source": [
    "### Approach 2: Using NLTK to parse terms into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbe967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some punctuations and concat hip&hop to avoid being seperated into two terms\n",
    "genre_list_cleaned\n",
    "genre_list_cleaned_punkt1 = [i.replace(\"-\",\"\") for i in genre_list_cleaned]\n",
    "genre_list_cleaned_punkt2 = [i.replace(\"&\",\"\") for i in genre_list_cleaned_punkt1]\n",
    "genre_list_cleaned_punkt3 = [i.replace(\"+\",\"\") for i in genre_list_cleaned_punkt2]\n",
    "genre_list_cleaned_punkt4 = [i.replace(\"hip hop\",\"hiphop\") for i in genre_list_cleaned_punkt3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa15230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer function\n",
    "def tokenize_content(content):\n",
    "    ''' \n",
    "    - convert input into lowercase, then tokenize each element\n",
    "    - remove words stopwords and words with non-alphabetic characters\n",
    "    - return a list of tokenized words\n",
    "    '''\n",
    "    s = content.lower()\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    token_words = [i for i in tokens if i not in stopwords and i.isalpha()]\n",
    "    return token_words\n",
    "\n",
    "# remove words stopwords and words with non-alphabetic characters\n",
    "top_tokens_list = [tokenize_content(i) for i in genre_list_cleaned_punkt4]\n",
    "top_tokens = [w for ls in top_tokens_list for w in ls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use COUNTER to count number of times a token showed up\n",
    "token_counter = Counter(top_tokens)\n",
    "\n",
    "# plot the word cloud using token_counter dictionary\n",
    "plt.subplots(figsize = (15,6))\n",
    "wordcloud = WordCloud (\n",
    "                    background_color = 'white',\n",
    "                    width = 512,\n",
    "                    height = 384\n",
    "                        ).generate_from_frequencies(token_counter)\n",
    "plt.imshow(wordcloud) # show wordcloud\n",
    "plt.axis('off') # to hide x and y axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3aabfe",
   "metadata": {},
   "source": [
    "## Run correlation matrix to remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4438c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = \"white\")\n",
    "corr = tracks_feature_df.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, cmap=\"RdBu\", vmax=1, vmin = -1, annot = True)\n",
    "plt.title(\"Correlation Heatmap\", fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae4e13",
   "metadata": {},
   "source": [
    "Since [loudness] and [acousticness] features are both highly correlated with [energy], we decided to keep [energy], which is a more intuitive feature. Also, the field [key] denotes scale such as C, C+, D, etc, which are hard for user to define, thus we decided to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb72d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_feature_df.drop(['loudness','acousticness','key'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b318c627",
   "metadata": {},
   "source": [
    "### Part III: K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff00cc",
   "metadata": {},
   "source": [
    "Before running K-Means, since K-Means is scale-variant, we need to standardize some of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c312ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to understand the min max of each numerical features\n",
    "min_max_df = pd.DataFrame()\n",
    "min_max_df['min'] = tracks_feature_df.min(axis = 0,numeric_only = True)\n",
    "min_max_df['max'] = tracks_feature_df.max(axis = 0,numeric_only = True)\n",
    "min_max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run standard scaler on column ['duration_ms_sc','tempo_sc'] which has a large range of value\n",
    "scaler = StandardScaler()\n",
    "feature_df_sc = scaler.fit_transform(tracks_feature_df[['duration_ms','tempo']])\n",
    "feature_df_sc = pd.DataFrame(feature_df_sc,columns = ['duration_ms_sc','tempo_sc'])\n",
    "feature_df_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8618cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with original df and keep only features for k-means clustering\n",
    "tracks_feature_df_sc = tracks_feature_df[['danceability',\n",
    "                                          'energy',\n",
    "                                          'mode',\n",
    "                                          'speechiness',\n",
    "                                          'instrumentalness',\n",
    "                                          'valence']].join(feature_df_sc)\n",
    "tracks_feature_df_sc.head()                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d737bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA with 2 components in order to visualize our clusters\n",
    "pca = PCA(n_components = 2) # 2D PCA for the plot\n",
    "# fit and transform the data\n",
    "tracks_feature_df_pca = pd.DataFrame(pca.fit_transform(tracks_feature_df_sc))\n",
    "tracks_feature_df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bf93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the kmeans model\n",
    "kmeans = KMeans(n_clusters=6, n_init= 20)\n",
    "# fit the input data\n",
    "kmeans = kmeans.fit(tracks_feature_df_pca)\n",
    "# get the cluster labels\n",
    "labels = kmeans.predict(tracks_feature_df_pca)\n",
    "# centroid values\n",
    "centroid = kmeans.cluster_centers_\n",
    "# cluster values\n",
    "clusters = kmeans.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d33be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append clustered result to PCA-ed df\n",
    "tracks_feature_df_pca['cluster'] = clusters\n",
    "# append track name to the PCA-ed df\n",
    "tracks_feature_df_pca['track_name'] = tracks_feature_df['track_name']\n",
    "# rename the columns of the pca-ed df\n",
    "tracks_feature_df_pca.columns = ['x', 'y', 'cluster', 'track_name']\n",
    "tracks_feature_df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f23a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the clusters\n",
    "%matplotlib inline\n",
    "sns.set(style=\"white\")\n",
    "ax = sns.lmplot(x=\"x\", y=\"y\", hue='cluster', data = tracks_feature_df_pca, legend=False,\n",
    "fit_reg=False, height = 5, scatter_kws={\"s\": 50})\n",
    "\n",
    "plt.xlabel(\"Component #1\", fontsize = 10)\n",
    "plt.ylabel(\"Component #2\", fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append cluster results to tracks_feature_df\n",
    "tracks_feature_df['cluster'] = clusters\n",
    "tracks_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('Downloads', exist_ok=True)  \n",
    "tracks_feature_df.to_csv('Downloads/tracks_feature_df.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
